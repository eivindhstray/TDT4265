{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Convolving the given image with the sobel kernel produces the following output:\n",
    "\n",
    "<div>\n",
    "<img src=\"Convolution_1a.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "Here, we have used zero-padding which is frequently used when applying spatial convolution. We could also have extended the borders or used other techniques, but zero padding also makes the operation simpler when computing by hand. I get the oposite values in Matlab(...?)\n",
    "\n",
    "-6 shoulb be 6!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1d)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1e)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1f)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "## task 1g)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "\n",
    "![](plots/task2.png)\n",
    "\n",
    "### Task 2b)\n",
    "\n",
    "The test accuracy ended up at 0.7301 or 73.01% while the test accuracy ended up at 72.62%. The final training accuracy was noticably higher at 81.25%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.4860### Task 3a)\n",
    "We improved the model step by step to see the impact of different actions. Adding dropout between each convolution layer with probaby of 0.2 after all max-pool layers resulted in less overfitting. The next thing was adding batch normalization between every layer which resulted in faster training.\n",
    "\n",
    "We then added data augmentation with the following transformations for the training set: \n",
    "- Horizontal rotation with probability of 0.5.\n",
    "- Random rotations between -20 and 20 degrees.\n",
    "- Conversion to grayscale with default probability of 0.1.\n",
    "\n",
    "Finally, we increased the learning rate by a factor of 10 from $10^{-2}$ to $10^{-1}$. This greatly impacted the training speed, surprisingly without making the training unstable. There was, however, clearer signs of overfitting.\n",
    "\n",
    "At this point, the test accuracy had increased from around 70% to close to 75%.\n",
    "\n",
    "We then decreased the training again to $5 \\cdot 10^{-2}$, in between the two previously attempted.\n",
    "\n",
    "Finally, we modified the first layer to consist of two convolution - ReLu layers before the first maxpooling, resulting in a test accuracy of 0.7624 and a validation accuracy of 0.7694.\n",
    "\n",
    "\n",
    "In the next model, we switched the ReLU function with the Sigmoid Linear Unit (SiLU) function after each convolution layer, which resulted in quite similar results. The test accuracy was now at 0.7603 while the validation accuracy was at 0.7642. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Model 1:\n",
    "\n",
    "| Layer      | Layer Type   | Filters/Hidden units  | Activation    |\n",
    "| :- | -: | :-: | :-: | \n",
    "| 1 | Conv2D | 16 | ReLU | \n",
    "| 1 | Conv2D | 32 | ReLu | \n",
    "| 1 | MaxPool2D | - | -| \n",
    "| 1 | Dropout | - | -| \n",
    "| 2 | Conv2D | 64 | ReLu | \n",
    "| 2 | MaxPool2D | - | -| \n",
    "| 2 | Dropout | - | -| \n",
    "| 3 | Conv2D | 128 | ReLu | \n",
    "| 3 | MaxPool2D | - | -| \n",
    "| 3 | Dropout | - | -| \n",
    "| - | Flatten | - | -| \n",
    "| 4 | FC | 64 | ReLU | \n",
    "| 5 | FC | 10 | SoftMax | \n",
    "\n",
    "\n",
    "#### Model 2:\n",
    "\n",
    "| Layer | Layer Type | Filters/Hidden units| Activation|\n",
    "| :- | -: | :-: | :-: | \n",
    "| 1 | Conv2D | 16 | SiLU | \n",
    "| 1 | Conv2D | 32 | SiLu | \n",
    "| 1 | MaxPool2D | - | -| \n",
    "| 1 | Dropout | - | -| \n",
    "| 2 | Conv2D | 64 | SiLU | \n",
    "| 2 | MaxPool2D | - | -| \n",
    "| 1 | Dropout | - | -| \n",
    "| 3 | Conv2D | 128 | SiLU | \n",
    "| 3 | MaxPool2D | - | -| \n",
    "| 3 | Dropout | - | -| \n",
    "| - | Flatten | - | -| \n",
    "| 4 | FC | 64 | ReLU | \n",
    "| 5 | FC | 10 | SoftMax | \n",
    "\n",
    "#### Other hyperparameters\n",
    "Both models were trained with the specifications given at the top of this section. \n",
    "These include data augmentation, dropout probability of 0.2 for all layers. Batch size remained at 64 for all the tests and for both networks, and the learning rate at $5*10^{-2}$. All convolution layers ended up with a kernel size of (3,3) and padding of size 1 which seemed to work better than (5,5) with padding of size 2.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Task 3b)\n",
    "\n",
    "| Model  |   Training accuracy | Testing accuracy | Validation accuracy| Training loss|\n",
    "| :-: | :-: | :-: | :-: | \n",
    "| 1 | 0.8291 | 0.7639 | 0.7592 | 0.4860|\n",
    "| 2 | 0.8326 | 0.7586 | 0.7654 | 0.4722|\n",
    "\n",
    "\n",
    "The plots for model 1 can be found below : \n",
    "\n",
    "![](plots/task3a_1.png)\n",
    " \n",
    "### Task 3c)\n",
    "\n",
    "We saw the greatest improvement with dropout, resulting in much less overfitting. This is not surprising, as dropout is frequently used as a way to prevent overfitting.\n",
    "\n",
    "Training speed was greatly affected by learning rate (not surprisingly), and for the network to converge within 10 epochs, increasing this by a factor of 5 was helpful. \n",
    "\n",
    "Data augmentation did also seemingly reduce overfitting a bit, although dropout was clearly more efficient. This is a balanced and quite large dataset, so perhaps data augmentation is not really the most dramatic change performance-wise.\n",
    "\n",
    "Increasing the depth of the network a bit (the first layer) with smaller kernels (3,3 instead of 5,5) increased the performance a bit. This could have to do with more details being picked up by the smaller kernels.\n",
    "\n",
    "### Task 3d)\n",
    "![](plots/task3c.png)\n",
    "### Task 3e)\n",
    "The best model from task 3b) has a test-accuracy of more than 80%, at  82.23%.\n",
    "### Task 3f)\n",
    "After expanding the network with different features in 3a), overfitting is significantly less occuring than in task 2. There is, however, a gap between validation and training which signifies that there is in fact some overfitting taking place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "![](plots/task4a.png)\n",
    "\n",
    "Batch size: 32\n",
    "\n",
    "Learning rate: $5\\cdot 10^{-4}\n",
    "\n",
    "Data augmentation: None\n",
    "\n",
    "Resize: 224\n",
    "\n",
    "Optimizer: Adam\n",
    "\n",
    "\n",
    "\n",
    "Final test accuracy: 0.8865"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "\n",
    "Passing the image through the first filter yields the following images for the selected indices:\n",
    "\n",
    "![](plots/filtering.png)\n",
    "\n",
    "It seems the first two and the third are essentially edge detectors while the others detect certain colors. Each activation will have different properties like this, and together they extract different features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "\n",
    "After a bit of playing around, we ended up with the following output which is the first 10 activations from the last convolution layer (after the last batch normalization which we were told was fine):\n",
    "\n",
    "![](plots/4c.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}